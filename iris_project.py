import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

# Configuraci√≥n de la p√°gina
st.set_page_config(page_title="Clasificaci√≥n de Especies de Iris", layout="wide", page_icon="üå∏")

# T√≠tulo principal
st.title("üå∏ Dashboard de Clasificaci√≥n de Especies de Iris")
st.markdown("---")

# Sidebar con informaci√≥n del proyecto
st.sidebar.header("üìä Informaci√≥n del Proyecto")
st.sidebar.markdown("""
**Proyecto Final de Miner√≠a de Datos**  
Universidad de la Costa  

**Integrantes del Equipo:**
- [Nombre 1]
- [Nombre 2]
- [Nombre 3]
- [Nombre 4]

**Profesor:** Jos√© Escorcia-Gutierrez, Ph.D.
""")

# Cargar y preparar datos
@st.cache_data
def cargar_datos():
    # Cargar el dataset desde CSV
    df = pd.read_csv('Iris.csv')
    return df

@st.cache_resource
def entrenar_modelo(X_train, y_train):
    # Entrenar modelo Random Forest
    modelo = RandomForestClassifier(n_estimators=100, random_state=42, max_depth=5)
    modelo.fit(X_train, y_train)
    return modelo

# Cargar datos
try:
    df = cargar_datos()
    
    # Preparar datos
    X = df[['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']]
    y = df['Species']
    
    # Dividir datos
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)
    
    # Escalar datos
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    
    # Entrenar modelo
    modelo = entrenar_modelo(X_train_scaled, y_train)
    
    # Predicciones
    y_pred = modelo.predict(X_test_scaled)
    
    # Calcular m√©tricas
    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred, average='weighted')
    recall = recall_score(y_test, y_pred, average='weighted')
    f1 = f1_score(y_test, y_pred, average='weighted')
    
    # Tabs principales
    tab1, tab2, tab3, tab4 = st.tabs(["üìà Resumen y M√©tricas", "üîç Exploraci√≥n de Datos", "üéØ Hacer Predicciones", "üìä An√°lisis del Modelo"])
    
    # TAB 1: Resumen y M√©tricas
    with tab1:
        st.header("M√©tricas de Rendimiento del Modelo")
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("Exactitud (Accuracy)", f"{accuracy:.4f}", delta="Alto Rendimiento")
        with col2:
            st.metric("Precisi√≥n", f"{precision:.4f}")
        with col3:
            st.metric("Exhaustividad (Recall)", f"{recall:.4f}")
        with col4:
            st.metric("Puntaje F1", f"{f1:.4f}")
        
        st.markdown("---")
        
        # Matriz de confusi√≥n
        st.subheader("Matriz de Confusi√≥n")
        cm = confusion_matrix(y_test, y_pred)
        
        fig_cm = px.imshow(cm, 
                           labels=dict(x="Predicci√≥n", y="Real", color="Cantidad"),
                           x=['Setosa', 'Versicolor', 'Virginica'],
                           y=['Setosa', 'Versicolor', 'Virginica'],
                           text_auto=True,
                           color_continuous_scale='Blues')
        fig_cm.update_layout(height=400)
        st.plotly_chart(fig_cm, use_container_width=True)
        
        # Workflow explicaci√≥n
        st.markdown("---")
        st.subheader("üîÑ Flujo de Trabajo del Proyecto")
        st.markdown("""
        **1. Comprensi√≥n de los Datos**
        - Se carg√≥ el dataset de Iris con 150 muestras y 4 caracter√≠sticas
        - Se explor√≥ la distribuci√≥n de clases y estad√≠sticas de las caracter√≠sticas
        
        **2. Preprocesamiento de Datos**
        - Se verific√≥ la ausencia de valores faltantes
        - Se aplic√≥ StandardScaler para normalizaci√≥n de caracter√≠sticas
        - Divisi√≥n de datos: 80% entrenamiento, 20% prueba con estratificaci√≥n
        
        **3. Selecci√≥n y Entrenamiento del Modelo**
        - Algoritmo: Clasificador Random Forest
        - Justificaci√≥n: Robusto ante sobreajuste, maneja relaciones no lineales, 
          proporciona informaci√≥n sobre importancia de caracter√≠sticas
        - Hiperpar√°metros: 100 estimadores, profundidad m√°xima=5
        
        **4. Evaluaci√≥n del Modelo**
        - Validaci√≥n cruzada para confiabilidad
        - M√∫ltiples m√©tricas para evaluaci√≥n comprehensiva
        - Matriz de confusi√≥n para an√°lisis detallado de errores
        """)
    
    # TAB 2: Exploraci√≥n de Datos
    with tab2:
        st.header("Exploraci√≥n de Datos")
        
        col1, col2 = st.columns([1, 2])
        
        with col1:
            st.subheader("Vista Previa del Dataset")
            st.dataframe(df.head(10), height=300)
            
            st.subheader("Estad√≠sticas del Dataset")
            st.write(f"**Total de Muestras:** {len(df)}")
            st.write(f"**Caracter√≠sticas:** {len(X.columns)}")
            st.write(f"**Clases:** {df['Species'].nunique()}")
            
            st.write("**Distribuci√≥n de Clases:**")
            class_counts = df['Species'].value_counts()
            st.write(class_counts)
        
        with col2:
            st.subheader("Distribuci√≥n de Caracter√≠sticas por Especie")
            feature_names = {
                'SepalLengthCm': 'Longitud del S√©palo (cm)',
                'SepalWidthCm': 'Ancho del S√©palo (cm)',
                'PetalLengthCm': 'Longitud del P√©talo (cm)',
                'PetalWidthCm': 'Ancho del P√©talo (cm)'
            }
            feature_select = st.selectbox("Seleccionar Caracter√≠stica", 
                                         list(feature_names.keys()),
                                         format_func=lambda x: feature_names[x])
            
            fig_dist = px.histogram(df, x=feature_select, color='Species', 
                                   marginal='box', 
                                   title=f'Distribuci√≥n de {feature_names[feature_select]}',
                                   barmode='overlay',
                                   opacity=0.7,
                                   labels={'Species': 'Especie'})
            st.plotly_chart(fig_dist, use_container_width=True)
        
        # Scatter matrix
        st.subheader("Relaciones entre Caracter√≠sticas")
        df_plot = df.copy()
        df_plot.columns = ['Id', 'Longitud S√©palo', 'Ancho S√©palo', 'Longitud P√©talo', 'Ancho P√©talo', 'Especie']
        
        fig_scatter = px.scatter_matrix(df_plot, 
                                       dimensions=['Longitud S√©palo', 'Ancho S√©palo', 'Longitud P√©talo', 'Ancho P√©talo'],
                                       color='Especie',
                                       title="Matriz de Dispersi√≥n de Todas las Caracter√≠sticas")
        fig_scatter.update_traces(diagonal_visible=False)
        st.plotly_chart(fig_scatter, use_container_width=True)
    
    # TAB 3: Hacer Predicciones
    with tab3:
        st.header("üéØ Predictor Interactivo de Especies")
        st.markdown("Ingresa las medidas de una flor de Iris para predecir su especie:")
        
        col1, col2 = st.columns([1, 2])
        
        with col1:
            st.subheader("Medidas de Entrada")
            
            sepal_length = st.slider("Longitud del S√©palo (cm)", 
                                    float(df['SepalLengthCm'].min()), 
                                    float(df['SepalLengthCm'].max()), 
                                    float(df['SepalLengthCm'].mean()),
                                    0.1)
            
            sepal_width = st.slider("Ancho del S√©palo (cm)", 
                                   float(df['SepalWidthCm'].min()), 
                                   float(df['SepalWidthCm'].max()), 
                                   float(df['SepalWidthCm'].mean()),
                                   0.1)
            
            petal_length = st.slider("Longitud del P√©talo (cm)", 
                                    float(df['PetalLengthCm'].min()), 
                                    float(df['PetalLengthCm'].max()), 
                                    float(df['PetalLengthCm'].mean()),
                                    0.1)
            
            petal_width = st.slider("Ancho del P√©talo (cm)", 
                                   float(df['PetalWidthCm'].min()), 
                                   float(df['PetalWidthCm'].max()), 
                                   float(df['PetalWidthCm'].mean()),
                                   0.1)
            
            # Realizar predicci√≥n
            input_data = np.array([[sepal_length, sepal_width, petal_length, petal_width]])
            input_scaled = scaler.transform(input_data)
            prediction = modelo.predict(input_scaled)[0]
            prediction_proba = modelo.predict_proba(input_scaled)[0]
            
            st.markdown("---")
            st.subheader("Resultado de la Predicci√≥n")
            st.success(f"**Especie Predicha:** {prediction}")
            
            st.write("**Niveles de Confianza:**")
            species_list = modelo.classes_
            for species, prob in zip(species_list, prediction_proba):
                st.write(f"{species}: {prob:.2%}")
        
        with col2:
            st.subheader("Visualizaci√≥n 3D")
            
            # Crear DataFrame para visualizaci√≥n
            df_viz = df.copy()
            df_viz['Tipo'] = 'Dataset'
            
            # Agregar el punto nuevo
            new_point = pd.DataFrame({
                'SepalLengthCm': [sepal_length],
                'SepalWidthCm': [sepal_width],
                'PetalLengthCm': [petal_length],
                'PetalWidthCm': [petal_width],
                'Species': [prediction],
                'Tipo': ['Nueva Muestra']
            })
            
            df_viz = pd.concat([df_viz, new_point], ignore_index=True)
            
            # Crear gr√°fico 3D
            fig_3d = px.scatter_3d(df_viz, 
                                  x='PetalLengthCm', 
                                  y='PetalWidthCm', 
                                  z='SepalLengthCm',
                                  color='Species',
                                  symbol='Tipo',
                                  title='Gr√°fico 3D: Posici√≥n de la Muestra en el Espacio de Caracter√≠sticas',
                                  opacity=0.7,
                                  size_max=10,
                                  labels={'PetalLengthCm': 'Longitud P√©talo (cm)',
                                         'PetalWidthCm': 'Ancho P√©talo (cm)',
                                         'SepalLengthCm': 'Longitud S√©palo (cm)',
                                         'Species': 'Especie',
                                         'Tipo': 'Tipo'})
            
            fig_3d.update_traces(marker=dict(size=5), selector=dict(name='Dataset'))
            fig_3d.update_traces(marker=dict(size=15, line=dict(width=2, color='DarkSlateGrey')), 
                               selector=dict(name='Nueva Muestra'))
            
            fig_3d.update_layout(height=600)
            st.plotly_chart(fig_3d, use_container_width=True)
    
    # TAB 4: An√°lisis del Modelo
    with tab4:
        st.header("üìä An√°lisis del Modelo")
        
        # Feature importance
        st.subheader("Importancia de las Caracter√≠sticas")
        feature_names_es = {
            'SepalLengthCm': 'Longitud del S√©palo',
            'SepalWidthCm': 'Ancho del S√©palo',
            'PetalLengthCm': 'Longitud del P√©talo',
            'PetalWidthCm': 'Ancho del P√©talo'
        }
        
        feature_importance = pd.DataFrame({
            'Caracter√≠stica': [feature_names_es[f] for f in X.columns],
            'Importancia': modelo.feature_importances_
        }).sort_values('Importancia', ascending=False)
        
        fig_imp = px.bar(feature_importance, 
                        x='Importancia', 
                        y='Caracter√≠stica', 
                        orientation='h',
                        title='Importancia de las Caracter√≠sticas en el Modelo Random Forest')
        st.plotly_chart(fig_imp, use_container_width=True)
        
        st.markdown("---")
        
        # An√°lisis detallado por clase
        st.subheader("Rendimiento por Clase")
        
        from sklearn.metrics import classification_report
        report = classification_report(y_test, y_pred, output_dict=True)
        
        report_df = pd.DataFrame(report).transpose()
        report_df = report_df[report_df.index.isin(['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'])]
        report_df.columns = ['Precisi√≥n', 'Exhaustividad', 'F1-Score', 'Soporte']
        
        st.dataframe(report_df.style.highlight_max(axis=0, color='lightgreen'))
        
        st.markdown("---")
        
        # Informaci√≥n del modelo
        st.subheader("Informaci√≥n del Modelo")
        col1, col2 = st.columns(2)
        
        with col1:
            st.write("**Tipo de Modelo:** Random Forest Classifier")
            st.write(f"**N√∫mero de Estimadores:** {modelo.n_estimators}")
            st.write(f"**Profundidad M√°xima:** {modelo.max_depth}")
            st.write(f"**Muestras de Entrenamiento:** {len(X_train)}")
            st.write(f"**Muestras de Prueba:** {len(X_test)}")
        
        with col2:
            st.write("**Caracter√≠sticas Utilizadas:**")
            for feat in X.columns:
                st.write(f"- {feature_names_es[feat]}")
            
            st.write("")
            st.write("**Justificaci√≥n del Modelo:**")
            st.write("- Robusto ante sobreajuste")
            st.write("- Maneja relaciones no lineales")
            st.write("- Proporciona importancia de caracter√≠sticas")
            st.write("- Excelente para datos tabulares")

except FileNotFoundError:
    st.error("‚ùå Error: No se encontr√≥ el archivo 'Iris.csv'. Aseg√∫rate de que el archivo est√© en el mismo directorio que este script.")
    st.info("Sube tu archivo Iris.csv para continuar.")
except Exception as e:
    st.error(f"‚ùå Ocurri√≥ un error: {str(e)}")

# Footer
st.markdown("---")
st.markdown("""
<div style='text-align: center'>
    <p>Universidad de la Costa - Proyecto Final de Miner√≠a de Datos</p>
    <p><em>"Las tres virtudes principales de un programador son: Pereza, Impaciencia y Arrogancia." - Larry Wall</em></p>
</div>
""", unsafe_allow_html=True)